# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Determine the number of latent factors in POET (approximate factor model)
#'
#' This function is for calculating the optimal number of factors in an
#' approximate factor model.
#'
#' (Copy from POET package) This method was proposed by Bai & Ng (2002) and
#' Hallin & Liska (2007). They propose two penalty functions and in turn
#' minimize the corresponding information criteria. Notice that this method may
#' underestimate K. POET is very robust to over-estimating K. But
#' under-estimating K can result to VERY BAD performance. Therefore we strongly
#' recommend choosing a relatively large K (normally less than 8) to avoid
#' missing any important common factor.
#'
#' IMPORTANT: the calculation of Hallin & Liska method (2007) is wrong in the
#' original POET package, here we only calculate the criteria from Bai & Ng
#' (2002).
#' 
#' @param Y p by n matrix of raw data, where p is the dimensionality, n is the
#'   sample size. It is recommended that Y is de-meaned, i.e., each row has
#'   zero mean.
#' @param kmax the given upper bound of number of factors. The optimal k is
#'   searched from 1 to kmax.
#' @return A vector with two elements
#' \item{K1BN}{(The 1st element) estimated number of factors based on the first infomation criterion using Bai & Ng method}
#' \item{K2BN}{(The 2nd element) estimated number of factors based on the second infomation criterion using Bai & Ng method}
#'
#' @references Hallin, M., & Liška, R. (2007). Determining the number of factors in the general dynamic factor model. Journal of the American Statistical Association, 102(478), 603-617.
#' @references Bai, J., & Ng, S. (2002). Determining the number of factors in approximate factor models. Econometrica, 70(1), 191-221.
#'
#' @examples
#' n <- 50; p <- 100; k <- 3
#' set.seed(1)
#' B <- matrix(rnorm(100 * 3), 100, 3)
#' F <- MASS::mvrnorm(n, rep(0, k), diag(1, k))
#' U <- MASS::mvrnorm(n, rep(0, p), diag(1, p))
#' Y <- t(F %*% t(B) + U)
#' poetREV::poet_Khat(Y)
#' poetREV::poet_Khat2(Y)
poet_Khat <- function(Y, kmax = 15L) {
    .Call(`_poetREV_poet_Khat`, Y, kmax)
}

#' POET Revised by Wenliang Ding
#'
#' Estimates large covariance matrices in approximate factor models by
#' thresholding principal orthogonal complements.
#'
#' (Copy from POET package) This function is for POET, proposed by Fan, Liao
#' and Mincheva (2012) 'Large Covariance Estimation by Thresholding Principal
#' Orthogonal Complements', manuscript of Princeton University
#'
#' Model: Y_t=Bf_t+u_t, where B, f_t and u_t represent factor loading matrix,
#' common factors and idiosyncratic error respectively. Only Y_t is
#' observable. t=1,...,n. Dimension of Y_t is p. The goal is to estimate the
#' covariance matrices of Y_t and u_t.
#'
#' Note: (1) POET is optimization-free, so no initial value, tolerant, or
#' maximum iterations need to be specified as inputs.
#'
#' (2) We can apply the adaptive thresholding (Cai and Liu 2011, JASA) on
#' either the correlation matrix or the covariance matrix, specified by the
#' option 'matrix'.
#'
#' (3) If no factor structure is assumed, i.e., no common factors exist and
#' var(Y_t) itself is sparse, set K=0.
#'
#' IMPORTANT: the calculation of Hallin & Liska method (2007) is wrong in the
#' original POET package, here we only calculate the criteria from Bai & Ng
#' (2002).
#' 
#' @param Y p by n matrix of raw data, where p is the dimensionality, n is the
#'   sample size. It is recommended that Y is de-meaned, i.e., each row has
#'   zero mean.
#' @param K number of factors. K is pre-determined by the users. Default value
#'   is set at the average value obtained from the Hallin&Liska and Bai&Ng
#'   methods. Suggestions on choosing K:
#'
#' A simple way of determining K is to count the number of very spiked (much
#' larger than others) eigenvalues of the p by p sample covariance matrix of Y.
#'
#' A formal data-driven way of determining K is described in Bai and Ng
#' (2002):"Determining the number of factors in approximate factor models",
#' Econometrica, 70, 191-221. This procedure requires a one-dimensional
#' optimization.
#'
#' POET is very robust to over-estimating K. But under-estimating K can result
#' to VERY BAD performance. Therefore we strongly recommend choosing a
#' relatively large K (normally less than 8) to avoid missing any important
#' common factor.
#' 
#' K=0 corresponds to threshoding the sample covariance directly.
#' @param C the positive constant for thresholding, user-specified. Default
#'   value is set at C=0.5 Our experience shows that C=0.5 performs quite well
#'   for soft thresholding.
#' @param thres choice of thresholding. Users can choose from three
#'   thresholding methods:
#' 
#' 'soft': soft thresholding;
#' 
#' 'hard' hard thresholding;
#' 
#' 'scad': scad thresholding;
#' 
#' 'alasso': adaptive lasso thresholding;
#' 
#' Default value is set at thres='soft'.
#' 
#' Details are found in Rothman et al. (2009): "Generalized thresholding of large covariance matrices." JASA, 104, 177-186
#' @param matrix the option of thresholding either correlation or covairance matrix. Users can choose from:
#' 
#' 'cor': threshold the error correlation matrix then transform back to covariance matrix
#' 
#' 'vad': threshold the error covariance matrix directly.
#' 
#' Default value is set at matrix='cor'.
#' 
#' @return A list with two elements
#' \item{SigmaY}{estimated p by p covariance matrix of y_t}
#' \item{SigmaU}{estimated p by p covariance matrix of u_t}
#'
#' @references Fan, J., Liao, Y., & Mincheva, M. (2013). Large covariance estimation by thresholding principal orthogonal complements. Journal of the Royal Statistical Society Series B: Statistical Methodology, 75(4), 603-680.
#'
#' @examples
#' n <- 50; p <- 100
#' set.seed(1)
#' Y <- t(MASS::mvrnorm(n, rep(0, p), diag(1, p)))
#' res_poet <- poetREV::poet(Y, NULL, .5, "soft", "cor")
#' ## res_poet$SigmaY
#' ## res_poet$SigmaU
#' res_poet2 <- poetREV::poet2(Y, -Inf, .5, "soft", "cor")
#' ## res_poet2$SigmaY
#' ## res_poet2$SigmaU
#' mean(abs(res_poet$SigmaY - res_poet2$SigmaY)) ## [1] 5.15726e-16
#' mean(abs(res_poet$SigmaU - res_poet2$SigmaU)) ## [1] 1.015261e-16
#' 
poet <- function(Y, K = NULL, C = .5, thres = "soft", matrix = "cor") {
    .Call(`_poetREV_poet`, Y, K, C, thres, matrix)
}

#' Cross-Validation of POET (non-parallel, Cpp version)
#'
#' Cross-Validation criterion is the Kullback–Leibler loss (KLL) function. Note
#' that the n observations are partitioned in order (not randomly), i.e. if n =
#' 100, 5-folds cv will use the partitions as follows: [1, ..., 20], [21, ...,
#' 40], [41, ..., 60], [61, ..., 80], [81, ..., 100].
#'
#' Cpp version of \code{\link[poetREV]{cv_poet_par}}, see
#' \code{\link[poetREV]{cv_poet_par}} for examples.
#' 
#' @param Y p by n data matrix.
#' @param K_seq sequence of K for cv. K is the number of latent factor.
#' @param C_seq sequence of C for cv. C is the shrinkage intensity.
#' @param thres shrinkage method.
#' @param matrix indicator of shrinkage matrix, "cor" (default) or "vad".
#' @param kfolds kfolds-cv.
#' @return A list with two elements
#' \item{params}{params expanded by K_seq and C_seq.}
#' \item{cri}{the calculated criteria across the params using kfolds-cv.}
#' \item{K_opt}{the optimal K over the K_seq.}
#' \item{C_opt}{the optimal C over the C_seq.}
#' @seealso \code{\link[poetREV]{cv_poet_par}}
cv_poet <- function(Y, K_seq, C_seq, thres = "soft", matrix = "cor", kfolds = 5L) {
    .Call(`_poetREV_cv_poet`, Y, K_seq, C_seq, thres, matrix, kfolds)
}

